\documentclass[a4paper,12pt]{article}

%%% Работа с русским языком
\usepackage{cmap}					% поиск в PDF
\usepackage{mathtext} 				% русские буквы в формулах
\usepackage[T2A]{fontenc}			% кодировка
\usepackage[utf8]{inputenc}			% кодировка исходного текста
\usepackage[english,russian]{babel}	% локализация и переносы

%%% Дополнительная работа с математикой
\usepackage{amsfonts,amssymb,amsthm,mathtools} % AMS
\usepackage{amsmath}
\usepackage{icomma} % "Умная" запятая: $0,2$ --- число, $0, 2$ --- перечисление

\usepackage[left = 2cm, right = 2cm, top = 2cm, bottom = 2cm]{geometry}


%% Номера формул
%\mathtoolsset{showonlyrefs=true} % Показывать номера только у тех формул, на которые есть \eqref{} в тексте.

%% Шрифты
\usepackage{euscript}	 % Шрифт Евклид
\usepackage{mathrsfs} % Красивый матшрифт

%% Свои команды
\DeclareMathOperator{\sgn}{\mathop{sgn}}

%% Перенос знаков в формулах (по Львовскому)
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
	{\hbox{$\mathsurround=0pt #1$}}{}}

%%% Работа с картинками
\usepackage{graphicx}  % Для вставки рисунков
\graphicspath{{images/}{images2/}}  % папки с картинками
\setlength\fboxsep{3pt} % Отступ рамки \fbox{} от рисунка
\setlength\fboxrule{1pt} % Толщина линий рамки \fbox{}
\usepackage{wrapfig} % Обтекание рисунков и таблиц текстом

%%% Работа с таблицами
\usepackage{array,tabularx,tabulary,booktabs} % Дополнительная работа с таблицами
\usepackage{longtable}  % Длинные таблицы
\usepackage{multirow} % Слияние строк в таблице
\usepackage{upgreek}
\usepackage{enumerate}
\usepackage{ dsfont }

%%% Цветной текст

\usepackage[usenames]{color}
\usepackage{colortbl}

%%% Солнышко

\usepackage[weather]{ifsym}

%%% Гиперссылки

\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{linkcolor}{HTML}{199B03} % цвет ссылок
\definecolor{urlcolor}{HTML}{199B03} % цвет гиперссылок

\hypersetup{pdfstartview=FitH,  linkcolor=linkcolor,urlcolor=urlcolor, colorlinks=true}

%\usepackage{minted}

%% эконометрические сокращения
\def \hb{\hat{\beta}}
\DeclareMathOperator{\sVar}{sVar}
\DeclareMathOperator{\sCov}{sCov}
\DeclareMathOperator{\sCorr}{sCorr}


\def \hs{\hat{s}}
\def \hy{\hat{y}}
\def \hY{\hat{Y}}
\def \he{\hat{\varepsilon}}
\def \v1{\vec{1}}
\def \cN{\mathcal{N}}
\def \e{\varepsilon}
\def \z{z}

\def \hVar{\widehat{\Var}}
\def \hCorr{\widehat{\Corr}}
\def \hCov{\widehat{\Cov}}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator*{\plim}{plim}

%% лаг
\renewcommand{\L}{\mathrm{L}}

% DEFS
\def \mbf{\mathbf}
\def \msf{\mathsf}
\def \mbb{\mathbb}
\def \tbf{\textbf}
\def \tsf{\textsf}
\def \ttt{\texttt}
\def \tbb{\textbb}

\def \wh{\widehat}
\def \wt{\widetilde}
\def \ni{\noindent}
\def \ol{\overline}
\def \cd{\cdot}
\def \bl{\bigl}
\def \br{\bigr}
\def \Bl{\Bigl}
\def \Br{\Bigr}
\def \fr{\frac}
\def \bs{\backslash}
\def \lims{\limits}
\def \arg{{\operatorname{arg}}}
\def \dist{{\operatorname{dist}}}
\def \VC{{\operatorname{VCdim}}}
\def \card{{\operatorname{card}}}
\def \sgn{{\operatorname{sign}\,}}
\def \sign{{\operatorname{sign}\,}}
\def \xfs{(x_1,\ldots,x_{n-1})}
\def \Tr{{\operatorname{\mbf{Tr}}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\amn}{arg\,min}
\DeclareMathOperator*{\amx}{arg\,max}
\def \cov{{\operatorname{Cov}}}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}

\def \xfs{(x_1,\ldots,x_{n-1})}
\def \ti{\tilde}
\def \wti{\widetilde}


\def \mL{\mathcal{L}}
\def \mW{\mathcal{W}}
\def \mH{\mathcal{H}}
\def \mC{\mathcal{C}}
\def \mE{\mathcal{E}}
\def \mN{\mathcal{N}}
\def \mA{\mathcal{A}}
\def \mB{\mathcal{B}}
\def \mU{\mathcal{U}}
\def \mV{\mathcal{V}}
\def \mF{\mathcal{F}}

\def \R{\mbb R}
\def \N{\mbb N}
\def \Z{\mbb Z}
\def \P{\mbb{P}}
%\def \p{\mbb{P}}
\def \E{\mbb{E}}
\def \D{\msf{D}}
\def \I{\mbf{I}}

\def \a{\alpha}
\def \b{\beta}
\def \t{\tau}
\def \dt{\delta}
\def \e{\varepsilon}
\def \ga{\gamma}
\def \kp{\varkappa}
\def \la{\lambda}
\def \sg{\sigma}
\def \sgm{\sigma}
\def \tt{\theta}
\def \ve{\varepsilon}
\def \Dt{\Delta}
\def \La{\Lambda}
\def \Sgm{\Sigma}
\def \Sg{\Sigma}
\def \Tt{\Theta}
\def \Om{\Omega}
\def \om{\omega}

%%% Заголовок
\author{Зехов Матвей}
\title{Домашне задание}
\date{\today}



\begin{document}
	\section{Данные}
	
	В этом домашнем задании вам предстоит работать с данными о лесных пожарах. Вы будете оценивать зависимость сгоревшей площади (area) от различных погодных условий. Данные и их описание можно найти по ссылке: 
	
	\href{https://archive.ics.uci.edu/ml/datasets/Forest+Fires}{https://archive.ics.uci.edu/ml/datasets/Forest+Fires}
	
\section{Правила}
	
В качестве решения принимаются следующие виды файлов:
\begin{enumerate}
	\item Jupyter notebook
	\item Rmd-файл с чанками кода, скомпилированный в PDF
	\item R-файл с ответам в виде комментариев
	
\end{enumerate}	

 Задачи одинаково решаемы на любом из двух языков программирования. Сдача скрипта без комментариев и/или плагиат кода караются нулём баллов. Использование Stata карается нулём баллов. Всего за работу можно получить 10 баллов максимум. Бонусами можно покрыть недочёты в других номерах, но имейте в виду, что они могут быть сложнее обычных задач. Куда деть избыток бонусов мы пока не придумали.
	
	Все таблицы и графики должны быть подписаны. Все оси у графиков тоже. Графики без осей/комментариев и прочих обязательных атрибутов оцениваться не будут. На защите диплома навряд ли кто-то станет проверять ваши числа в таблицах, а вот отсутствие подписи будет резать глаз. Если в задаче не указана визуализация, но вы считаете, что она необходима, ни в чём себе не отказывайте. 

Не забывайте фиксировать seed для воспроизводимости результатов.
	
	\section{Задания}
	
	\begin{enumerate}
		\item 0 баллов
		
		 Подготовьте данные. Для простоты отфильтруйте нулевые значения целевой переменной, так как модели с цензурированными выборками в эту работу не входят. Преобразуйте категориальные переменные, если считаете это необходимым. Сделайте иные преобразования данных, если считаете их необходимыми (например, бинаризация признаков или логарифмирование). Обоснуйте свои преобразования.
		
		\item 1.5 балла
		
		Отберите признаки, которые вы включите в модель. Кратко обоснуйте, почему вы берёте каждый признак, и какой знак вы ожидаете получить при соответствующей переменной в линейной модели. Нет ограничений по количеству и набору переменных, важно, чтобы он был логичен и обоснован. Однко желательно принять во внимание нелинейные признаки и признаки взаимодействия.
		
		Подготовьте описательные статистики данных. Обязательные: среднее, медиана, дисперсия, минимум, максимум. Дополнительные -- любые по желанию. Например, отвергается ли гипотеза о нормальности теста Шапиро-Уилка и что-то ещё.
		
		Визуализируйте ваши признаки. Обязательно: гистограммы и ящики с усами. Иное -- по желанию. Проинтерпретируйте графики. Есть ли в данных выбросы или иные аномалии? Если да, то как вы планируете с ними работать.
		
		\item 1 балл
		
		Проверьте, есть ли в ваших данных мультиколлинеарность. Используйте для этогого VIF и CN. Если мультиколлинеарность присутствует, разберитесь с ней как настоящие ковбои. 
		
		
		\item 
		0.5 балла
		
		 Оцените линейную модель и проинтерпретируйте результаты. Как можно объяснить знаки, которые не совпали с вашими исходными предположениями? Получились ли переменные значимы по отдельности и в целом? В данном пункте не следует ожидать высокого $ R^2 $ из-за особенностей данных. Игнорируйте этот факт. Такие мелочи не должны вас волновать, ведь вы занимаетесь наукой.
		 
		 Протестируйте остатки на нормальность любым из тестов.
		 
		 Бонус 1 балл.
		 
		  Если остатки вашей модели получились не нормальными, вероятно предпосылка о нормальности случайных ошибок тоже нарушается. Воспользуйтесь процедурой бутстрепа и получите эмпирические доверительные интервалы.
		 Алгоритм описан в этом видео:
		 \href{https://www.youtube.com/watch?v=UBSExb568B8}{https://www.youtube.com/watch?v=UBSExb568B8} Обратите внимание, что случайная выборка генерируется с возвращением.
		
		
		\item 0.5 баллов
		
		 Постройте следующие прогнозы: точечный, индивидуальный и для среднего. В качестве значений независимых переменных возьмите медианные значения наблюдений.
		
		\item 0.5 баллов
		
		Предположите, какие из регрессоров могут порождать гетероскедастичность. Обоснуйте идейно зависимость между этими переменными и дисперсией ошибок.
		
		\item 1 балл
		
		 Попытайтесь выявить гетероскедастичность по предположенным ранее переменным двумя способами: графически с помощью остатков регрессионной модели и вручную проведите тест Голдфельда-Квандта. Если не найдёте имплементации в любом из языков (маловероятно), реализуйте тест самостоятельно. Совпали ли результаты?
		
		\item 1.5 балла
		
		 Вне зависимости от того, обнаружена ли гетероскедастичность в предыдущих пунктах, вручную (в матрицах) оцените модель взвешенного МНК. Разумеется, предположите, что ковариационная матрица ошибок диагональна. Засчитывается как использование пакетных реализаций, так и решение вручную в матрицах, но в обоих случаях надо предоставить коэффициенты, стандартные ошибки и p-value.
		 
		Изменились ли результаты значимости по сравнению с обычной линейной моделью?
		
		\item 1 балл
		
		 Вычислите робастные ошибки в форме Уайта (HC0), лучше вместо пакетных реализаций построить вручную. Поясните метод расчёта (можно на словах, главное - идея). Вычислите p-value для всех переменных. Изменились ли результаты значимости по сравнению с обычной линейной моделью?
		 
		 Бонус 1 балл
		 
		 Повторите для HC3
		
	
		\item 1.5 балл
		
		Преобразуйте ваши независимые переменные с помощью PCA. Какую долю дисперсии объясняют две первые главные компоненты? Постройте линейную регрессию зависимой переменной на две первые главные компоненты и проинтерпретируйте результат. Повысилась ли объясняющая способность модели относительно обычной линейной? Значимы ли переменные? 
		
		\item 1 балл Весёлая задача на десятку
		
		С помощью метода максимального правдоподобия получите оценки линейной модели. Для этого в явном виде в матричной форме выпишите функцию правдоподобия.Далее найдите оценки коэффициентов (дисперсии ошибок -- по желанию) двумя способами:
		
		\begin{enumerate}
			\item Решите задачу аналитически (совпадёт с МНК, просто перепишите предыдущий результат)
			
			\item Решите задачу с помощью методов численного дифференцирования. В случаях когда градиент трудно выписать в явной форме, его можно вычислить приближённо, через приращения. Пример кода для функции нескольких переменных приложен в письме с домашним заданием, обобщите его на векторный случай. Напишите функцию, вычисляющую приближённый вектор-градиент правдоподобия в точке. Так как эта задача выпуклая, отлично справится обычный градиентный спуск без дополнительных наворотов. Если кто-то забыл или не знал, что это такое:
			
			 \href{https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/lecture02-linregr.pdf}{https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/lecture02-linregr.pdf}
			
		\end{enumerate}
	
		Похожи ли результаты?
	\end{enumerate}
	

\end{document}