---
output: html_document

---
# Стохастические бобры и прочие условности {#12_everything_about_beavers}

Дата: **05.12.2016** 

Авторы: **Уманец Екатерина, Купцова Анастасия**

## Упражнение № 0 
**Дано**

\begin{tabular}{c|rrrr|}
u/x & 2 & 3  \\
\hline
-1 & 0.1 & 0.2\\
\hline
1 & 0.1 & 0.6\\
\hline
\end{tabular}

u,x - скалярные случайные величины

**Хотим найти**

$E(u|x)? \\ Var(u|x)?$

**Решение**

$E(u|x=2)=0,5*(-1)+0,5*1=0 \\ 
E(u|x=3)=-1*0,25 +1*0,75$

\[
E(u|x) =
\begin{cases}
0, & \text{если $x=2$;} \\
0,5, & \text{если $x=3$.}
\end{cases}
 = 0,5(x-2)\]
 

$Var(u|x)=E(u^2|x)-E^2(u|x)$

$E(u^2|x)=1\Rightarrow$

\[
Var(u|x) =
\begin{cases}
1/3, & \text{$x=2$;} \\
3/4, & \text{$x=3$.}
\end{cases}
=1-0,25(x-2)^2\]

## Условные свойства

$1.E(f(x)|x)=f(x) \\
2. Var(f(x)|x)=0 \\
3. E(f(x)y|x)=f(x)E(y|x)\\
4. E(E(y|x))=E(y)\\
5. Var(y)=Var(E(y|x))+E(Var(y|x))\\$

## Упражнение № 1

**Дано:**

$x_1,x_2...$

$x_i\sim N(10,9)$ - независимы


$\underbrace{
\overbrace{(x_1,u_1)}^{can \ be \ dependent}
\rm (x_2,u_2)}_{independent}...$ \ - независимы \ и \ одинаково \ распеделены


\[ X=\begin{pmatrix} x_1 \\ : \\ x_n\end{pmatrix} ,u=\begin{pmatrix} u_1 \\ : \\ u_n\end{pmatrix}\]

**Хотим найти**

$a) plim(\frac {1}{n}X'X)^{-1}$

$b) plim(\frac {1}{n}X'u)$

$c) plim(X'X)^{-1}X'u$

**Решение**

ЗБЧ:
$Y_1,..,Y_n$ - независимы и одинаково распределены

$\bar{Y_n}\longrightarrow E(Y_1)$


$a) plim(\frac{1}{n}\sum_{1}^{n} x_i^2)^{-1}= (plim(\frac{1}{n} \sum_{1}^{n}x_i^2))^{-1} =E(x_1^2)^{-1}=(9+100)^{-1}=\frac{1}{109}$

$b) plim(\frac {1}{n}X'u) = [\frac{X'u}{n}=\frac{\sum(x_iu_i)}{n}]=E(x_i,u_i)=E(E(x_i,u_i|x)) = E(x_i\underbrace{E(u_i|x_i)}_{=0}=0\\$

$c)plim(X'X)^{-1}X'u=plim(\frac{1}{n}X'X)^{-1}\frac{1}{n}X'u=plim(\frac{1}{n}X'X)^{-1}*plim(\frac{1}{n}X'u)=109^{-1}*0=0$

## Случайность? Не думаю! Или история о том, как отличить стохастические и́ксы

Будем исследовать такой воспрос: как количество выпитого кофе влияет на производительность Бориса.

* **Эксперимент №1** (*неслучайные иксы*):пригласим 100 рандомных Борисов, попросим Бориса номер один в первый день выпить одну кружку кофе, Бориса номер два во второй - две, и так далее, скажем, сто дней; соответственно, на сотый день сотый Борис будет пить сто кружек кофе; и посмотрим, сколько брутальных задачек по эконометрике каждый Борис сможет решить в каждый из этих дней.  **Внимание:** В данном экмперименте ни один Борис не пострадал!!!



* **Эксперимент №2** (*стохастические иксы*): поймаем 100 рандомных Борисов на улице и спросим, сколько кружек кофе каждый из них пьет и сколько брутальных задач решает за день. 

Главное отличие между этими двумя экспериментами заключается в том, что в первом случае мы сами выбирали количество кружек кофе, а во втором эта величина получалась случайно.

## Теорема (как на все это смотрели Гаусс и Марков)

**Если:**

* $y = X\beta + u$ - наша регрессионная модель со стохастическими иксами

* $(\chi_{i|\dots}, {y}_{i})$ - независимы и одинаково распределены (то есть между парами зависимостей нет, а вот внутри пары - угадайте что:) ), где $\chi_{i|\dots}$ - $i$-ая строка матрицы $X$

* $E({u}_{i}|\chi_{i|\dots}) = 0$

* $Var({u}_{i}|\chi_{i|\dots}) = \sigma^2$ - условие гомоскедастичности

* $P(столбцы\ матрицы\ X\ линейно\ независимы) = 1$

**Тогда:**
 
* $E(\hat{\beta}|X) = \beta$ и $E(\hat{\beta}) = \beta$

* $Var(\hat{\beta}|X) = {\sigma^2}(X^{T}X)^{-1}$

* $\hat{\beta}$ линейна по $y$

* $\hat{\beta}$ эффективна среди линейных по $y$ и несмещенных оценок

* $plim(\hat{\beta}) = \beta$

## А что если гетероскедастичность?

Пусть выполняются все предположения предыдущей теоремы, кроме одного - гомоскедастичности. То есть теперь $Var({u}_{i}|\chi_{i|\dots}) = f(\chi_{i|\dots})$ - условие гетероскедастичности.

**Тогда хотим найти:**

1. $\Omega$ = $Var(u|X)$ = $?$

2. $E(\hat{\beta}|X)$ = $?$

3. $Var(\hat{\beta}|X)$ = $?$

4. $plim(\hat{\beta})$ = $?$

**Решение:**

1. $\Omega$ = $Var(u|X)$ = $\begin{pmatrix}
f(\chi_{1|\dots}) & \cdots & 0\\
\vdots & 	\ddots & 	\vdots\\
0 & \cdots & f(\chi_{n|\dots})
\end{pmatrix}$

Теперь поймем, откуда это взялось:

* во-первых, $Var({u}_{i}|X)$ = $Var({u}_{i}|\chi_{i|\dots})$ =  $f(\chi_{i|\dots})$ - элементы на диагонали матрицы $\Omega$

* во-вторых, $Cov({u}_{i}, {u}_{j}|X)$ = $0$ - элементы вне диагонали матрицы $\Omega$

2. $E(\hat{\beta}|X)$ = $\beta$

Действительно:

$E(\hat{\beta}|X)$  = $E({(X^{T}X)^{-1}}X^{T}y|X)$ = ${(X^{T}X)^{-1}}X^{T}E(y|X)$

Так как $E(y|X)$ = $E(X\beta + u|X)$ = $X\beta + E(u|X)$ = $X\beta + 0$ (**Note**: $E(u|X)$ = $0$ следует из предпосылок теоремы, а именно $E({u}_{i}|\chi_{i|\dots}) = 0$),

то $E(\hat{\beta}|X)$  = ${(X^{T}X)^{-1}}X^{T}E(y|X)$ = ${(X^{T}X)^{-1}}X^{T}X\beta$ = $1*\beta$ = $\beta$

3. $Var(\hat{\beta}|X)$ = ${(X^{T}X)^{-1}}X^{T}{\Omega}{X}{(X^{T}X)^{-1}}$

Докажем, что на самом деле получается именно такая сэндвич-формула:

$Var(\hat{\beta}|X)$ = $Var({(X^{T}X)^{-1}}X^{T}y|X)$ = ${(X^{T}X)^{-1}}X^{T}Var(y|X)({(X^{T}X)^{-1}}X^{T})^{T}$ = ${(X^{T}X)^{-1}}X^{T}Var(y|X){X}{(X^{T}X)^{-1}}$ 

Так как $Var(y|X)$ = $Var(X\beta + u|X)$ = $Var(u|X)$ = $\Omega$,

то $Var(\hat{\beta}|X)$  = ${(X^{T}X)^{-1}}X^{T}Var(y|X){X}{(X^{T}X)^{-1}}$ = ${(X^{T}X)^{-1}}X^{T}{\Omega}{X}{(X^{T}X)^{-1}}$

4. $plim(\hat{\beta})$ = $\beta$ 

Докажем это:

$plim(\hat{\beta})$ = $plim({(X^{T}X)^{-1}}X^{T}y)$  = $plim({(X^{T}X)^{-1}}X^{T}(X\beta + u))$ = $plim({(X^{T}X)^{-1}}X^{T}X\beta)$  + $plim({(X^{T}X)^{-1}}X^{T}u)$ = $\beta$ + $plim({(X^{T}X/n)^{-1}}X^{T}u/n)$ = $\beta$ + $plim{(X^{T}X/n)^{-1}}*plim(X^{T}u/n)$ = [эти пределы мы уже искали в упражнении 1] = $\beta$ + $const*0$ = $\beta$

**Как Уайт предлагает оценивать дисперсию оценки** $\beta$ :

$\hat{Var}(\hat{\beta}|X)$ = ${(X^{T}X)^{-1}}X^{T}{\hat{\Omega}}{X}{(X^{T}X)^{-1}}$

где ${\hat{\Omega}}$ = $\begin{pmatrix}
{\hat{u}_{1}}^{2} & \cdots & 0\\
\vdots & 	\ddots & 	\vdots\\
0 & \cdots & {\hat{u}_{n}}^{2}
\end{pmatrix}$

## В чем прелесть гетероскедастичности?

А вот в чем - зная о гетероскедастичности, мы знаем распределение:

$\frac{\hat{{\beta}_{j}} - {\beta}_{j}}{{SE}_{HC}(\hat{{\beta}_{j}})}$ ~ $N(0,1)$ - асимптотически, конечно!