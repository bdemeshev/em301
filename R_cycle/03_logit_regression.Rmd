# Logit и probit модели в R

Загружаем библиотеки
```{r, message=FALSE}
library(erer) # предельные эффекты, заодно подтянет пакеты ggplot2, lmtest
library(ggplot2) # графики
library(lmtest) 
library(foreign)
library(xtable)
library(texreg)
```

Загружаем [данные](https://github.com/bdemeshev/em301/raw/master/datasets/mesto_jenshini.dta) в R:
```{r}
h <- read.dta("../datasets/mesto_jenshini.dta")
```

Это данные американского социологического опроса National Longitudinal Survey of Youth. Основная переменная, `agree`, показывает согласна ли опрашиваемая женщина с утверждением "Место женщины у плиты!" Мы оценим logit и probit модели для переменной `agree`.

![](03_plita.gif)

Андрей Цветков, ["Место женщины"](http://ccra.ru/Plk)

## До оценки моделей

Проверяем, что всё корректно загрузилось --- `.dta` это не родной для R формат. 
```{r}
head(h)
summary(h)
```

Let's look on some specific variables. Income. Probably year income divided by family size.
```{r}
summary(h$adjinc)
```

Несколько графиков до построения моделей:
```{r}
qplot(factor(agree),data=h)
# more with ggplot2
```

## Собственно оценка моделей

Логит, пробит и мнк. Предпосылки применения мнк нарушены, но мы его всё равно применим и посмотрим, что выйдет.
```{r}
m.logit <- glm(agree~age+adjinc+nsibs,
          data=h,x=TRUE,
          family=binomial(link="logit"))
m.probit <- glm(agree~age+adjinc+nsibs,
          data=h,x=TRUE,
          family=binomial(link="probit"))
m.ols <- glm(agree~age+adjinc+nsibs,
          data=h)
```

Посмотрим на логит модель:
```{r}
summary(m.logit)
```

Ковариационную матрицу оценок коэффициентов раздобыть легко
```{r}
vcov(m.logit)
```


Коэффициенты в логит и пробит моделях плохо интерпретируемы, т.к. скрытая переменная, в данной задаче  склонность к ответу "да", измеряется в непонятных единицах. В дополнение к коэффициентам рассчитывают предельные эффекты. Предельные эффекты отвечают на вопрос, как изменится примерно вероятность `y=1` с ростом регрессора на единицу. Обычно предельные эффекты считаются для среднего значения каждого регрессора:
```{r}
maBina(m.logit)$out
```
Опция `x=TRUE` в функции `glm` нужна только для того, чтобы работала функция `maBina`. Она сохраняет исходные `x` в полученной регрессии. Если массив данных огромный, то эту опцию можно убрать, но тогда придется считать предельные эффекты ручками.

### Сообщения об ошибках

* fitted probabilities numerically 0 or 1 occurred. Означает, что при итерациях при поиске максимума правдоподобия для какого-то наблюдения оцененные вероятности были настолько близки к нулю или единице, что у компьютера не хватает ячейки памяти, чтобы их отличить от нуля или единицы. Само по себе это нестрашно.
* algorithm did not converge. Можно попробовать увеличить количество итераций, иногда это помогает. В сочетании с предыдущим сообщением может быть показателем того, что 0 и 1 идеально разделяются какой-то переменной и возможно [<<идеальное>> прогнозирование](http://stats.stackexchange.com/questions/45803).


## Прогнозы

Создаем набор данных, для которого мы будем строить прогнозы:
```{r}
new <- data.frame(age=c(20,24),
                  adjinc=c(16000,4000),
                  nsibs=c(2,5))
new
```

В логит и пробит-моделях можно прогнозировать значение скрытой переменной (склонности ответить "да") или вероятность $y_i=1$ (вероятность ответить "да"). Прогноз скрытой переменной:
```{r}
predict(m.logit,new)
```

Немножко другой командой получаются прогнозы вероятности $y_i=1$:
```{r}
predict(m.logit,new,type="response")
```

Поскольку в методе максимального правдоподобия оценка любого параметра является асимпотически нормальной, то доверительный интервал для любого параметра $a$ строится по принципу $[\hat{a}-z_{cr}se(\hat{a});\hat{a}+z_{cr}se(\hat{a})]$. Для того, чтобы получить стандартные ошибки, как для оценки ожидаемой склонности ответить "да", так и для оценки вероятности ответить "да", используется опция `se.fit=TRUE`.

Поскольку чаще всего нужен доверительный интервал именно для вероятностей, мы построим только его. Если нужен доверительный интервал для ожидаемой склонности ответить да, то он строится аналогично:

```{r}
forecast <- predict(m.logit,new,type="response",se.fit=TRUE)
new$hat.p <- forecast$fit
new$se.hat.p <- forecast$se.fit
z.cr <- qnorm(0.975)
new$ci.left <- new$hat.p - z.cr * new$se.hat.p
new$ci.right <- new$hat.p + z.cr * new$se.hat.p
new
```


Заметим приятный факт. Для средних значений регрессоров обычный МНК, который формально нельзя применять из-за нарушения предпосылок теоремы Гаусса-Маркова, даёт вполне корректные прогнозы:


Проблемы МНК видны на краевых значениях регрессоров. Тут запросто могут быть отрицательные вероятности :)



Binary prediction. Best binary prediction?


## Выбор между вложенными моделями

Likelihood ratio, LR-test, Тест отношения правдоподобия
```{r}
m2.logit <- glm(agree~age+age2+adjinc+nsibs,
          data=h,
          family=binomial(link="logit"))
lrtest(m.logit,m2.logit)
```

Lagrange multiplier test, LM-test, тест множителей Лагранжа (? by hands)

Wald-test, Тест Вальда
```{r}
waldtest(m.logit,m2.logit,test="Chisq")
```






## Кривые ROC




ROC ручками...





ROC с помощью пакета ROCR

## Презентация результатов в латехе


Одна модель:
```{r, eval=FALSE}
xtable(m.logit)
```

Предельные эффекты одной модели:
```{r, eval=FALSE}
xtable(maBina(m.logit)$out)
```

Табличка со сравнением нескольких моделей:
```{r,eval=FALSE}
texreg(list(m.logit,m2.logit))
```

Табличка со сравнением предельных эффектов
```{r, eval=FALSE}

```


